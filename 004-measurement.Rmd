# (PART) Experimental design and planning {-}

::: {learning-goals}
Learning goals: Summarize differences between measurement reliability and validity; reason about appropriate cognitive psychology measures; identify well-constructed survey questions.
:::

# Measurement

As we've discussed earlier, the goal of an experiment is to make a (maximally precise and unbiased) measurement of a particular causal effect of interest. In this next section of the book, we're going to try to figure out how to do that. This chapter focuses on the topic of measurement.^[As a topic, measurement is actually much less well-discussed in experimental contexts compared with, say, observational studies. As far as we can tell, this is a sociological fact, not a scientific one. No matter whether you can manipulate the world directly (as in an experiment) or whether you are doing observational or quasi-experimental research, good measurement is the name of the game.]

No matter where you are working in the sciences, you need to measure things. If you're doing physics or chemistry, you need to be able to measure physical quantities; if you're doing biology you might measure populations or lifespan as well as a host of physical quantities. Proper measurement instruments are incredibly important for this kind of work, though in much standard science they are taken as a given.^[A lot could be said, of course, about the transformative value of better measurement instruments ].


::: {.case-study}
MacArthur Bates CDI (Fenson et al., 1994; Frank et al., 2021) as an example of a measure of a construct where we can step through validity and reliability as well as discuss the pros and cons of adopting this measure as an experimental outcome.
:::


## Attack of the psychometricians

In olden times, all the psychologists went to the same conferences and worried about the same things. But then a split formed between different groups. Educational psychologists and psychometricians knew that different problems on tests had different measurement properties, and began exploring how to select good and bad items, and how to figure out people's ability abstracted away from specific items. Cognitive psychologists, on the other hand, spurned this item-level variation and embraced the dogma of exchangeable experimental items.

People did Lots Of Trials, all generated from the same basic template. The sumscore^[The sumscore is just what we normal psychologists call "percent correct" -– treating the sum of your correct answers on the test as your score, as opposed to inferring the latent trait (ability) from the performance on the observed variables.] reigned supreme, and yielded important insight into Memory, Attention, and Reasoning (irrespective of what was being remembered, attended to, or reasoned about). 

Psychophysicists diverged from the cognitivist hierarchy. They always knew that they needed to infer a latent relationship. As they got better at doing this, they fit models that included parameters of the decision process (for example, a "lapse" parameter to capture inattention) as well as the quantities of interest. And because they typically fit these curves within individual subjects, these parameters were participant-level estimates. But the models that fit these curves were often specific to particular metric relationships and not appropriate for increasingly complicated domains.

Now in modern cognitive science, we get work on sophisticated constructs – for example, in moral psychology or psycholinguistics – where experimenters break with the cognitivist dogma and use non-exchangeable items. Sometimes items are sentences or even whole vignettes. Yet for the most part these researchers have forgotten to model item variation (except occasionally using a random intercept for items in their linear mixed effects models). @clark1973 scolded them about the problematic statistical inferences that could result from forgetting to model items and this guidance has reappeared in recent exhortations to Keep It Maximal! [@barr2013]. But as far as I can tell, no one really talks about modeling items in more detail *in order to learn more about what is in people's heads*.


## Measurement Validity

Does the measure relate to the construct? Classic concurrent and predictive validation strategies.

Face and ecological validity.
The nomological network (Cronbach and Meehl 1955). In other words, the measure is valid if it fits into the theory and is supported by other aspects of the theory.

## Measurement Reliability

Test-retest. Variance related to the test-taker’s performance. 	
Inter-rater. Variance related to the measurement method.

## Design of measures

Data types: Stevens (1946) framework.
Classic cognitive psychology measures: Forced choices and reaction times
Likert scales and asking good survey-style questions.

The promise and perils of open-ended measures. 

## Conclusions
