# (PART) Before you begin your experiment {-}

# Introduction: theory and experiments {#intro}

::: {.learning-goals}
üçé Learning goals: Define ‚Äúexperiment‚Äùand ‚Äútheory‚Äù, distinguish between bias and precision, reason about the relationship between the experimental method and causal inference, and analyze features of an experiment that can lead to weaker or stronger tests of theory. 
:::

::: {.case-study}
üî¨ Case study: the Rational Speech Act model of pragmatics as a model of the closed loop between theory and data (Goodman and Frank 2016).
:::

```{marginfigure, echo=TRUE}
<img src="images/rsa.png"/>
```

## What is an experiment and why do one? 

- On one hand, experiments are ‚Äúthe worst way to learn about the world‚Äù (in the words of one of our mentors). ‚ÄúYou can‚Äôt play 20 questions with nature and win‚Äù (Newell 1973). But experiments are also one of our best tools for making strong causal inferences about the hidden structure of the world. They allow us to not just observe the world but to systematically intervene on it.
- We used to just poke things or people and measure what happened (see Hacking, 1990 on the 19th century craze of just measuring everything for fun.) Now we typically want our experiments to resolve deeper questions or test hypotheses.
- Causal graphical models as an approach to understanding causal inference via counterfactuals (Pearl and Mackenzie 2018).

## What is a theory? 

The entities we theorize about are unseen. We call these **constructs**.^[Why are they called constructs? HISTORY OF THE TERM?] Constructs are hypothesized abstract entities, which can range widely in specificity. g (general intelligence) is the classic psychological example of a broad construct. In contrast, an example of a very specific construct is $\alpha$, the "rationality" parameter in RSA models that controls how greedily RSA agents choose the higher-probability choice.^[A tradition of research in cognitive science posits that human knowledge is organized into theories [@carey1989,@gopnikwellman], and that in particular we organize our knowledge about other people into an **intuitive theory of psychology**. This intuitive theory includes concepts like "belief," "desire," and "emotion" [@wellmanXYZ], but it's important to distinguish the constructs we posit in psychological theories from the terms in our intuitive theories. Often one is grounded in the other, but the failure to distinguish the two can lead to sloppy reasoning..]

Theories then are groups of assumptions about the relationships between these constructs. Occasionally, defining a construct is enough to describe a theory. Defining general intelligence as g, the shared variance between different tests of intelligence, is itself a theoretically-loaded move [critique of IQ here? maybe cite Shalizi]. But more frequently the constructs don't mean anything by themselves (think about $\alpha$ in RSA!) -- they gain their meaning by their relationship to other constructs. 

This web of constructs and assumptions is what @cronbach1958 referred to as a "nomological network" -- a set of proposals about how different entities are connected to one another.  (We'll return to this idea in Chapter \@ref(measurement) when we talk about measurement validity). Calling the theory a "network" sounds like it's a **structural equation model** (SEM) where there are circles and lines and the lines represent something akin to the correlations between the numbers in the circles. That's one way to define a psychological theory, but it's not the only way! 

There are many different frameworks for describing psychological constructs and their relationships. SEM is just one framework, built on linear regression. But the probabilistic modeling framework used in RSA is another such framework, where a system of equations defines a conditional probability distribution [@probmods]. Other computational frameworks from procedural models like ACT-R [@anderson] to connectionist models [@rethinkinginnateness] and modern neural networks [@naturereviewbengio] provide other frameworks. 

None of these computational or formal artifacts are themselves psychological theories, but all of them can be used to create psychological theories via the mapping of constructs onto entities in the model and the use of the principles of the formalism to instantiate psychological hypotheses or assumptions. ^[We might also want to add to the theory some assumptions about how these constructs ground out into measurements. Some philosophers of science distinguish between the "core" assumptions of a theory and the "periphery" -- and we might be tempted to say that specific measurements are peripheral. If we came up with a better measure of the construct, or it turned out that our measure wasn't particularly good, we could replace it without too much damage to the underlying theory.]

Theories can then be tested via their ability to explain existing patterns of data and to predict new data. There is some tension between these. Theories with high predictive value are not necessarily causal or parsimonious (e.g., a black-box neural network model that predicts heart disease risk). Meanwhile, theories with high explanatory value may only account for a small proportion of overall variance in a behavior (e.g. a theory of lexical priming that introduces a new, causal role of accessibility).

::: {.ethics-box}
üåø Ethics box: Who are we theorizing about? How does this theory build on prior history? And what are the consequences of that theorizing? Example: the input-uptake relationship in language learning is a well-supported idea, but it can become weaponized against communities of color (Sperry, Sperry, and Miller 2019).
:::

## How to do experiments that help build theory?

- Introducing the concepts of precision and bias (dartboard analogy).
    - Precision of measurement is a foundational value allowing for cumulative progress and falsification; measuring null effects with precision can be just as important.
    - Precise measurements must also be unbiased to be helpful in theory construction ‚Äì or else theories risk reifying bias into their constructs.
- "Risky tests" (Meehl 1978) vs. "flexible theories" (Roberts and Pashler 2000)
    - Formal relationship to Bayes Occam‚Äôs Razor and example of spreading bets across every horse vs. placing all your money on one horse (if that one horse wins, you get a much higher payoff in the second case).
- Each experiment can be viewed as a single operationalization of an underlying theory, thus the value of meta-analysis to pool across these instantiations (see Chapter 16).
