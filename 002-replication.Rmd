# Replication, reproducibility, and transparency  {#replication}

::: {.learning-goals}
üçé Learning goals: 

* Understand the "crisis" narrative in psychology and the empirical evidence supporting it
* Define the distinction between reproducibility and replicability
* Consider types of replication 
* Reason about the relation of replication to theory building
:::

In the previous chapter, we gave a sober and considered introduction to the topic of experiments, their connection with causal inference, and their role in building psychological theory. In this chapter we're going to change gears a little bit and tell the story of the period from 2011 -- 2021 and how it has given rise to a number of "crisis" narratives in psychology. 

We're also going to abandon the sober tone of the introduction and try to get you a bit worked up. From an empirical perspective, things have been far from ideal in the psychology literature. Many classic findings may be wrong, or at least overstated. Their statistical tests are probably not trustworthy. The actual numbers are even wrong in many papers! And even when experimental findings are "real" they may not reflect deep psychological generalizations. And even if they do, they likely don't reflect generalizations that are true about people in general, only some very specific groups of people. 

Your hair should be on fire, at least a little bit. If you by the end of this chapter, you don't feel a little bit of despair about the published psychological literature, then we haven't done our job!

## The meta-science of replicability and reproducibility

We have to start with some definitions. 

```{r}

```


### Reproducibility

Critical notion of the "provenance chain" for specific numbers - that they can be traced back to analytic computations. 

### Replication

## A framework for replication 

- We describe the framework for replication in Zwaan et al. (2018), highlighting the idea of multiple dimensions on which a replication can differ from the original study and the ways that this complicates inferences about replication ‚Äúsuccess‚Äù (Mathur and VanderWeele 2019, 2020).
- We can get different epistemic value from doing direct replications (attempt to copy original study with as much fidelity as possible) vs. conceptual replications (attempt to somewhat perturb operationalization of original study).

::: {.accident-report}
‚ö†Ô∏è Accident report: The "small telescopes" case study of Simonsohn et al. (2015): what if weather really does affect mood, but the effect is too small for the original study to ever detect?

> Imagine I claimed our next-door neighbor was a billionaire oil sheik who kept thousands of boxes of gold and diamonds hidden in his basement. Later we meet the neighbor, and he is the manager of a small bookstore and has a salary 10% above the US average... Should we describe this as ‚Äúwe have confirmed the Wealthy Neighbor Hypothesis, though the effect size was smaller than expected‚Äù? Or as ‚ÄúI made up a completely crazy story, and in unrelated news there was an irrelevant deviation from literally-zero in the same space‚Äù?
:::

## Relation to theory ubuilding

How do reproducibility and replicability contribute to theory building? We draw on Hardwicke et al. (2018), considering these factors in the informativeness of an experiment.


Introduce p-hacking and publication biases as major sources of irreproducibility. These are biases - and we highlight bias reduction as a key goal.


::: {.accident-report}
‚ö†Ô∏è Accident report: When I'm 64?

Simmons, Simonsohn, Nelson introduce p-hacking into our lexicon. 

:::




::: {.case-study}
üî¨ Case study: Hardwicke et al. (2018; 2021) meta-studies of the analytic reproducibility of specific analytic findings in the empirical literature.
:::
