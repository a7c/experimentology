# (PART) Preliminaries {-}

# Introduction: theory and experiments {#intro}

::: {.learning-goals}
üçé Learning goals: 

* Define ‚Äúexperiment‚Äùand ‚Äútheory‚Äù
* Distinguish between bias and precision 
* Reason about the relationship between the experimental method and causal inference
* Analyze features of an experiment that can lead to weaker or stronger tests of theory
:::


Welcome to Experimentology. This is a book about how to do psychology experiments! Much of what we cover in the book is about the nitty gritty of how to design your study, how to analyze your data, or even how to name your files! But before we can get into all that, we're going to need to have a conversation about what an experiment is. And that in turn will lead us pretty quickly to talk about **causality**, since the unique contribution of experiments is to help us measure causal effects. That's the first part of this chapter. 

The second part of this chapter is about the broader goals of doing experiments. Sometimes you just want to see what happens, like a kid knocking down a tower. And sometimes you want to know the answer to a specific applied question, like "will taking one midterms vs. weekly quizzes lead students in a class to perform better on the final." But more often, our goal is to create psychological theories that help us explain and predict new observations. Thus, the second half of this chapter will be about theories. 

Having discussed experiments and theories, we will then be in a position to talk a bit about what positions an experiment well to contribute to theory, our last topic. But, as we'll do in most chapters in the book, we'll begin with a concrete example of an interaction between theory and experiment.

<!-- the Rational Speech Act model of pragmatics as a model of the closed loop between theory and data (Goodman and Frank 2016). -->

::: {.case-study}
üî¨ Case study: Generalization, similarity, and Bayesian inference

Let's play a number game. Imagine I give you the number 16, and ask you how similar other numbers are to that one. You'll probably agree that 32 is more similar than 33. Is 96 more similar than 94? How about 6 vs. 8? Perhaps surprisingly, people's judgments on such problems are quite systematic [@tenenbaum2000]: the more "features" that two numbers share, the more similar they are judged to be. Not only is 32 even like 16, it's also a power of 2, and divisible by 8; in contrast, 33 shares none of these features. 

Predicting arbitrary similarities of this sort is one of the hardest problems of psychology, and is liked to one of the biggest challenges for organisms: generalization. How do you take what you know and apply it to a new situation? One answer is that you use the same answer that has worked in similar situations -- but to do this kind of extrapolation, you need a notion of similarity. 

Early learning theorists were obsessed with these issues of similarity and generalization because their view was that organisms (humans being no exception) learned conditioned associations with specific stimuli and then generalized from these associations to determine their response to new situations. So an animal conditioned to salivate to a tone of a particular frequency might salivate slightly less to a tone that was close in pitch, and salivate substantially less or not at all to a tone that was further away. 

Roger Shepard worked for much of his career on understanding this problem of similarity and generalization, culminating in what he called the "universal law of generalization," which allowed generalizations to be derived in a wide range of stimulus spaces [@shepard1987]. The first step in this process was establishing a stimulus space. For a stimulus domain like size, color, or even speech sounds, he used a procedure called "multi-dimensional scaling" to infer how stimulus items could be placed in a low-dimensional (often 2D) cartesian space. Then, when he visualized generalization gradients within this space, he found the incredibly consistent pattern shown in Figure \@ref(fig:shepard). Working backwards from this pattern, he was able to establish a derivation for this exponential generalization gradient that allowed him to claim it as a universal law.

```{r shepard, fig.cap="Figure 1 from Shepard (1987). Generalization gradients for twelve diffent kinds of stimuli.", fig.margin=TRUE}
knitr::include_graphics("images/intro/shepard1987.png")
```

Could it be that the "number game" judgments above are the same kinds of generalizations that Shepard observed in his analyses of perceptual data? @tenenbaum2001 presented a theory of similarity that preserved almost all of Shepard's assumptions, but did not require a continuous metric space at all, allowing it to be used to compute similarity and generalization for arbitrary domains, even the features of whole numbers! When they applied this model to human judgments from the number game they found a close correspondence with the probabilities given by their model. 

Since the development of this generalization model, it has been applied to a wide variety of domains including word learning [@xu2007], object exploration [@gweon2010], and sequential rule learning [@frank2011]. Yet it


As Shepard wrote in the conclusion of his paper, "Possibly, behind the diverse behaviors of humans and animals, as behind the various motions of planets and stars, we may discern the operation of universal laws." 
:::


## What is an experiment?

- On one hand, experiments are ‚Äúthe worst way to learn about the world‚Äù (in the words of one of our mentors). ‚ÄúYou can‚Äôt play 20 questions with nature and win‚Äù (Newell 1973). But experiments are also one of our best tools for making strong causal inferences about the hidden structure of the world. They allow us to not just observe the world but to systematically intervene on it.
- We used to just poke things or people and measure what happened (see Hacking, 1990 on the 19th century craze of just measuring everything for fun.) Now we typically want our experiments to resolve deeper questions or test hypotheses.

### Causal inference

- Causal graphical models as an approach to understanding causal inference via counterfactuals (Pearl and Mackenzie 2018).
  



Every year, one of the trickiest concepts for me to teach in my experimental methods course is the difference between experimental confounds and covariates. Although this distinction seems simple, it's pretty deeply related to the definition of what an experiment is and why experiments lead to good causal inferences. It's also caught up in a number of methodological problems that come up again and again in my class. This post is my attempt to explain the distinction and how it relates to different problems and cultural practices in psychology.

Throughout this post, I'll use a silly example. My first year of graduate school, I got distracted from my actual research by the hypothesis that listening to music with lyrics decreased my ability to write papers for my classes. I'll call this the "Bob Dylan" hypothesis, since I was listening to a lot of Dylan at the time. Let's represent this by the following causal diagram.

```{marginfigure, echo=TRUE}
<img src="images/dylan1.png"/>
```


Our outcome is writing skill (Y) and our predictor is Dylan listening (X). The edge between them represents a hypothesized causal relationship. Dylan is hypothesized to affect writing skill, and not vice versa. (These kinds of diagrams are called causal graphical models*).

Suppose we did an observational study where we measured each of these variables in a large population. Assume we came up with some way to sample people's writing, get a measure of whether they either were or weren't listening to lyric-heavy music at the time, and assess the writing sample's quality. We might find that Y was correlated with X, but in a surprising direction: listening to Dylan would be related to better writing.

Can we make a causal inference in this case? If so, we could get rich promoting a Dylan-based writing intervention. Unfortunately, we can't ‚Äì correlation doesn't equal causation here, because there is (at least one) confounding third variable: age (Z). Age is positively related to both Dylan listening and writing skill in our population of interest. Older people tend to be good writers and also tend to be more into folk rockers; I'm not even going to put a question mark on this edge because I'm pretty sure this is true.

```{marginfigure, echo=TRUE}
<img src="images/dylan2.png"/>
```

But: the causal relationship of age to our other two variables means that variation in Z can induce a correlation in X and Y, even in the absence of a true causal link. We can say that age is a confound in estimating the Dylan-writing skill relationship: it's a variable that is correlated with both our predictor and our outcome variables.

To get gold-standard evidence about causality, we need to do an experiment. (We won't discuss statistical techniques for inferring causality, which can be useful but don't give you gold standard evidence anyway; review here).

Experiments are when we intervene on the world and measure the consequences. Here, this means forcing some people to listen to Dylan. In the language of graphical models, if we control the Dylan listening, that means that variable X is causally exogenous. (Exogenous means that it's not caused by anything else in the system). We "snipped" the causal link between age and Dylan listening.

```{marginfigure, echo=TRUE}
<img src="images/dylan3.png"/>
```

So now we can "wiggle" the Dylan listening variable ‚Äì change it experimentally ‚Äì and see if we detect any changes in writing skill. We do this by randomly assigning individuals to listen to Dylan or not and then measuring writing during the assigned listening (or non-listening) period. This is a "between-subjects" design. We can use our randomized experiment to get a measure of the average treatment effect of Dylan, the size of the causal effect of the intervention on the outcome. 

<!-- In this simple experiment, the ATE is estimated by the regression Y ~ X (for ease of exposition, I'm not going to discuss so-called mixed models, which model variation across subjects and/or experimental items). That's the elegant logic of randomized experiments: the difference between condition gives you the average effect. -->

## What is a theory? 

The entities we theorize about are unseen. We call these **constructs**.^[Why are they called constructs? HISTORY OF THE TERM?] Constructs are hypothesized abstract entities, which can range widely in specificity. g (general intelligence) is the classic psychological example of a broad construct. In contrast, an example of a very specific construct is $\alpha$, the "rationality" parameter in RSA models that controls how greedily RSA agents choose the higher-probability choice.^[A tradition of research in cognitive science posits that human knowledge is organized into theories [@carey1989,@gopnikwellman], and that in particular we organize our knowledge about other people into an **intuitive theory of psychology**. This intuitive theory includes concepts like "belief," "desire," and "emotion" [@wellmanXYZ], but it's important to distinguish the constructs we posit in psychological theories from the terms in our intuitive theories. Often one is grounded in the other, but the failure to distinguish the two can lead to sloppy reasoning..]

Theories then are groups of assumptions about the relationships between these constructs. Occasionally, defining a construct is enough to describe a theory. Defining general intelligence as g, the shared variance between different tests of intelligence, is itself a theoretically-loaded move [critique of IQ here? maybe cite Shalizi]. But more frequently the constructs don't mean anything by themselves (think about $\alpha$ in RSA!) -- they gain their meaning by their relationship to other constructs. 

This web of constructs and assumptions is what @cronbach1958 referred to as a "nomological network" -- a set of proposals about how different entities are connected to one another.  (We'll return to this idea in Chapter \@ref(measurement) when we talk about measurement validity). Calling the theory a "network" sounds like it's a **structural equation model** (SEM) where there are circles and lines and the lines represent something akin to the correlations between the numbers in the circles. That's one way to define a psychological theory, but it's not the only way! 

There are many different frameworks for describing psychological constructs and their relationships. SEM is just one framework, built on linear regression. But the probabilistic modeling framework used in RSA is another such framework, where a system of equations defines a conditional probability distribution [@probmods2]. Other computational frameworks from procedural models like ACT-R [@anderson] to connectionist models [@rethinkinginnateness] and modern neural networks [@naturereviewbengio] provide other frameworks. 

None of these computational or formal artifacts are themselves psychological theories, but all of them can be used to create psychological theories via the mapping of constructs onto entities in the model and the use of the principles of the formalism to instantiate psychological hypotheses or assumptions. ^[We might also want to add to the theory some assumptions about how these constructs ground out into measurements. Some philosophers of science distinguish between the "core" assumptions of a theory and the "periphery" -- and we might be tempted to say that specific measurements are peripheral. If we came up with a better measure of the construct, or it turned out that our measure wasn't particularly good, we could replace it without too much damage to the underlying theory.]

Theories can then be tested via their ability to explain existing patterns of data and to predict new data. There is some tension between these. Theories with high predictive value are not necessarily causal or parsimonious (e.g., a black-box neural network model that predicts heart disease risk). Meanwhile, theories with high explanatory value may only account for a small proportion of overall variance in a behavior (e.g. a theory of lexical priming that introduces a new, causal role of accessibility).


### Popper, Kuhn, and Lakatos, oh my!

popper

lakatos

kuhn

bayesian theories

::: {.ethics-box}
üåø Ethics box: Who are we theorizing about? How does this theory build on prior history? And what are the consequences of that theorizing? Example: the input-uptake relationship in language learning is a well-supported idea, but it can become weaponized against communities of color (Sperry, Sperry, and Miller 2019).
:::

## How to do experiments that help build theory?

- Introducing the concepts of precision and bias (dartboard analogy).
    - Precision of measurement is a foundational value allowing for cumulative progress and falsification; measuring null effects with precision can be just as important.
    - Precise measurements must also be unbiased to be helpful in theory construction ‚Äì or else theories risk reifying bias into their constructs.
- "Risky tests" (Meehl 1978) vs. "flexible theories" (Roberts and Pashler 2000)
    - Formal relationship to Bayes Occam‚Äôs Razor and example of spreading bets across every horse vs. placing all your money on one horse (if that one horse wins, you get a much higher payoff in the second case).
- Each experiment can be viewed as a single operationalization of an underlying theory, thus the value of meta-analysis to pool across these instantiations (see Chapter 16).

- Experiments as "bets" - riskier or costlier bets more impressive


## What does an ideal experiment look like?

a bet
a formula
an aesthetic object



