# Statistical inference for comparing groups {#inference}

::: {.learning-goals}
üçé Learning goals: Reconceptualize statistical ‚Äútests‚Äù as models of data; build intuitions about how specific ‚Äútests‚Äù (e.g., t-tests) relate to more general frameworks (e.g., regression, mixed effects models); identify which models are best suited for which research questions; reason about effect effect size as estimated by statistical models.
:::

::: {.case-study}
üî¨ Case study: the ‚Äúlady tasting tea‚Äù example (Salsburg 2001) ‚Äì building intuitions about when statistical inference is important and what the limitations for this paradigm are. Historical origins of handling variability in measurement (Porter 2020).
:::

How to go from theory to hypotheses to statistical model

  - Krushke & Liddell (2018) taxonomy: Bayesian vs. frequentist, inference vs. estimation
  - Intuition builder: For very large n, or flat prior, Bayes and frequentist coincide. 

Introducing simple inference models:

  - The chi-squared test for inferring whether two samples come from the same distribution
  - The t-test for inferring whether a single group‚Äôs effect differs from 0
  - The t-test for inferring whether two groups differ from one another
  - The paired t-test as a first glimpse at how we might account for participant-level random effects (see Chapter 7).

::: {.interactive}
‚å®Ô∏è Interactive box: non-parametric simulations where you can shuffle data across groups a bunch of times and see what kind of distribution it produces by chance
:::

::: {.accident-report}
‚ö†Ô∏è Accident report: Once you have the basic t-test under your belt, it might feel natural to compare each group to 0 and conclude that one group is different from 0 and the other one isn‚Äôt. But ‚Äúthe difference between significant and not significant is not necessarily itself statistically significant‚Äù (Nieuwenhuis, Forstmann, and Wagenmakers 2011). 
:::

Effect size: a common language for describing group differences. Pros and cons of this approach. Pro: comparability across studies. Con: loss of information about measures and real-world predictions; dependence on baseline variability. 
