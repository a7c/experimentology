<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 4 Estimation | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 4 Estimation | Experimentology">

<title>Chapter 4 Estimation | Experimentology</title>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.18/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="toc/toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-intro.html#intro"><span class="toc-section-number">1</span> Experiments and Theories</a></li>
<li><a href="2-replication.html#replication"><span class="toc-section-number">2</span> Replication and reproducibility</a></li>
<li><a href="3-ethics.html#ethics"><span class="toc-section-number">3</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="4-estimation.html#estimation"><span class="toc-section-number">4</span> Estimation</a></li>
<li><a href="5-inference.html#inference"><span class="toc-section-number">5</span> Inference</a></li>
<li><a href="6-models.html#models"><span class="toc-section-number">6</span> Models</a></li>
<li class="part"><span><b>III Design and Planning</b></span></li>
<li><a href="7-measurement.html#measurement"><span class="toc-section-number">7</span> Measurement</a></li>
<li><a href="8-design.html#design"><span class="toc-section-number">8</span> Design of experiments</a></li>
<li><a href="9-sampling.html#sampling"><span class="toc-section-number">9</span> Sampling</a></li>
<li><a href="10-prereg.html#prereg"><span class="toc-section-number">10</span> Preregistration</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="11-selection.html#selection"><span class="toc-section-number">11</span> Replicating or extending an existing study</a></li>
<li><a href="12-collection.html#collection"><span class="toc-section-number">12</span> Data collection</a></li>
<li><a href="13-management.html#management"><span class="toc-section-number">13</span> Data management and sharing</a></li>
<li class="part"><span><b>V Analysis and Reporting</b></span></li>
<li><a href="14-viz.html#viz"><span class="toc-section-number">14</span> Visualization</a></li>
<li><a href="15-eda.html#eda"><span class="toc-section-number">15</span> Exploratory data analysis</a></li>
<li><a href="16-writing.html#writing"><span class="toc-section-number">16</span> Reproducible writing</a></li>
<li><a href="17-meta.html#meta"><span class="toc-section-number">17</span> Meta-analysis</a></li>
<li><a href="18-conclusions.html#conclusions"><span class="toc-section-number">18</span> Conclusions</a></li>
<li class="part"><span><b>VI Appendices</b></span></li>
<li><a href="19-github.html#github"><span class="toc-section-number">19</span> Github Tutorial</a></li>
<li><a href="20-rmarkdown.html#rmarkdown"><span class="toc-section-number">20</span> R Markdown Tutorial</a></li>
<li><a href="21-tidyverse.html#tidyverse"><span class="toc-section-number">21</span> Tidyverse Tutorial</a></li>
<li><a href="22-ggplot.html#ggplot"><span class="toc-section-number">22</span> ggplot Tutorial</a></li>
<li><a href="23-instructors.html#instructors"><span class="toc-section-number">23</span> Instructor’s Guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="estimation" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Estimation</h1>
<p>Idea of a sampling distribution</p>
<div id="a-probabilistic-framework" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> A probabilistic framework</h2>
<p>NEEDS TO BE FIXED WITH RESPECT TO CASE STUDY</p>
<p>An alternative way to frame our statistical practice is to start from the idea of estimation.</p>
<p>Let’s say we want to estimate some quantity, we’ll call it <span class="math inline">\(h\)</span> – our belief about the participant’s accuracy.<label for="tufte-sn-35" class="margin-toggle sidenote-number">35</label><input type="checkbox" id="tufte-sn-35" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">35</span> Technically, other specifications of random-effects meta-analysis are possible. For example, robust variance estimation does not require making assumptions about the distribution of effects across studies (<span class="citation"><label for="tufte-mn-84" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-84" class="margin-toggle">Hedges, Tipton, and Johnson (2010)<span class="marginnote">Hedges, Larry V, Elizabeth Tipton, and Matthew C Johnson. 2010. <span>“Robust Variance Estimation in Meta-Regression with Dependent Effect Size Estimates.”</span> <em>Research Synthesis Methods</em> 1 (1): 39–65.</span></span>). These approaches also have other substantial advantages, like their ability to handle effects that are clustered (e.g., because some papers contribute multiple estimates; <span class="citation"><label for="tufte-mn-85" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-85" class="margin-toggle">Hedges, Tipton, and Johnson (2010)<span class="marginnote">Hedges, Larry V, Elizabeth Tipton, and Matthew C Johnson. 2010. <span>“Robust Variance Estimation in Meta-Regression with Dependent Effect Size Estimates.”</span> <em>Research Synthesis Methods</em> 1 (1): 39–65.</span></span>; <span class="citation"><label for="tufte-mn-86" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-86" class="margin-toggle">Pustejovsky and Tipton (2021)<span class="marginnote">Pustejovsky, James E, and Elizabeth Tipton. 2021. <span>“Meta-Analysis with Robust Variance Estimation: Expanding the Range of Working Models.”</span> <em>Prevention Science</em>, 1–14.</span></span>) and their ability to provide better inference in meta-analyses with relatively few studies (<span class="citation"><label for="tufte-mn-87" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-87" class="margin-toggle">Tipton (2015)<span class="marginnote">Tipton, Elizabeth. 2015. <span>“Small Sample Adjustments for Robust Variance Estimation with Meta-Regression.”</span> <em>Psychological Methods</em> 20 (3): 375.</span></span>). For these reasons, we tend to use these methods by default when conducting meta-analyses.</span> We observe some data <span class="math inline">\(d\)</span>, consisting of the set of correct and incorrect responses in the experiment. Now we can use <strong>Bayes’ rule</strong>, a tool from basic probability theory, to estimate this number.</p>
<p>Bayes’ rule says:</p>
<p><span class="math display">\[
\color{purple}{p(h | d)} = \frac{\color{red}{p(d | h)} \color{blue}{p(h)}}{\color{black}{p(d)}}.
\]</span> Each part of this equation has a name, and it’s worth becoming familiar with them. The thing we want to compute (<span class="math inline">\(p(h|d)\)</span>) is called the <strong>posterior probability</strong> – it tell us what we should believe about the participant’s ability given the data we observed. We then break that down into two terms in the numerator.<label for="tufte-sn-36" class="margin-toggle sidenote-number">36</label><input type="checkbox" id="tufte-sn-36" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">36</span> The estimate of <span class="math inline">\(\widehat{\tau}^2\)</span> is a bit more complicated, but is essentially a weighted average of studies’ residuals, <span class="math inline">\(\widehat{\theta_i} - \widehat{\mu}\)</span>, while subtracting away variation due to statistical error, <span class="math inline">\(\widehat{\sigma}^2_i\)</span> (<span class="citation"><label for="tufte-mn-88" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-88" class="margin-toggle">DerSimonian and Laird (1986)<span class="marginnote">DerSimonian, Rebecca, and Nan Laird. 1986. <span>“Meta-Analysis in Clinical Trials.”</span> <em>Controlled Clinical Trials</em> 7 (3): 177–88.</span></span>; <span class="citation"><label for="tufte-mn-89" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-89" class="margin-toggle">Brockwell and Gordon (2001)<span class="marginnote">Brockwell, Sarah E, and Ian R Gordon. 2001. <span>“A Comparison of Statistical Methods for Meta-Analysis.”</span> <em>Statistics in Medicine</em> 20 (6): 825–40.</span></span>).</span></p>
<p>The first part of the numerator is <span class="math inline">\(p(d|h)\)</span>, the probability of the data we observed given our hypothesis about the participant’s ability. This part is called the <strong>likelihood</strong>.<label for="tufte-sn-37" class="margin-toggle sidenote-number">37</label><input type="checkbox" id="tufte-sn-37" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">37</span> For example, one approach to investigate moderators in meta-analysis is meta-regression, in which moderators (e.g., type of intergroup contact) are included as covariates in a random-effects meta-analysis model (<span class="citation"><label for="tufte-mn-90" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-90" class="margin-toggle">Thompson and Higgins (2002)<span class="marginnote">Thompson, Simon G, and Julian PT Higgins. 2002. <span>“How Should Meta-Regression Analyses Be Undertaken and Interpreted?”</span> <em>Statistics in Medicine</em> 21 (11): 1559–73.</span></span>). As in standard regression, coefficients can then be estimated for each moderator, representing the mean difference in population effect between studies with versus without the moderator.</span> This term tells us about the relationship between our hypothesis and the data we observed – so if we think the participant has high ability (say <span class="math inline">\(h = .9\)</span>) then the probability of a bunch of low accuracy observations will be fairly low.</p>
<p>The second term in the numerator, <span class="math inline">\(p(h)\)</span>, is called the <strong>prior</strong>. This term encodes our beliefs about how likely our participant is to have different levels of ability. Intuitively, if we think that they are very unlikely to have high tea discrimination ability, we should require more evidence to convince us of a particular level of discrimination. In contrast, if we think they are likely to have this ability, we should be easier to convince.</p>
<div class="figure"><span id="fig:inference-bayes-demo"></span>
<p class="caption marginnote shownote">
Figure 4.1: Examples of Bayesian inference about tea discrimination ability under three different priors (facets). Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior.
</p>
<img src="experimentology_files/figure-html/inference-bayes-demo-1.png" alt="Examples of Bayesian inference about tea discrimination ability under three different priors (facets). Blue lines give the prior probability distribution, red lines give the likelihood of the data, and purple lines give the posterior distribution from combining likelihood and prior." width="\linewidth"  />
</div>
<p>Figure <a href="4-estimation.html#fig:inference-bayes-demo">4.1</a> gives an example of the combination of prior and data.<label for="tufte-sn-38" class="margin-toggle sidenote-number">38</label><input type="checkbox" id="tufte-sn-38" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">38</span> However, evidence is mixed regarding whether including gray literature actually reduces across-study biases in meta-analysis (<span class="citation">(<a href="#ref-tsuji2019addressing" role="doc-biblioref"><strong>tsuji2019addressing?</strong></a>)</span>, <span class="citation"><label for="tufte-mn-91" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-91" class="margin-toggle">Mathur and VanderWeele (2021)<span class="marginnote">Mathur, Maya B, and Tyler J VanderWeele. 2021. <span>“Estimating Publication Bias in Meta-Analyses of Peer-Reviewed Studies: A Meta-Meta-Analysis Across Disciplines and Journal Tiers.”</span> <em>Research Synthesis Methods</em> 12 (2): 176–91.</span></span>).</span> For the sake of this example, we assume that we have run 12 tea discrimination trials and observed 9 successes and 3 failures. The evidence alone – with no prior – suggests a discrimination estimate of <span class="math inline">\(9/12 = .75\)</span>.<label for="tufte-sn-39" class="margin-toggle sidenote-number">39</label><input type="checkbox" id="tufte-sn-39" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">39</span> Essentially, funnel plots and most related methods can detect publication bias in which (1) small studies with large positive point estimates are more likely to be published than small studies with small or negative point estimates; and (2) the largest studies are published regardless of the magnitude of their point estimates. Funnel plots may not detect publication bias that favors significant results. For more detail on these points, see <span class="citation"><label for="tufte-mn-92" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-92" class="margin-toggle">Maier, VanderWeele, and Mathur (2021)<span class="marginnote">Maier, Maximilian, Tyler J VanderWeele, and Maya B Mathur. 2021. <span>“Using Selection Models to Assess Sensitivity to Publication Bias: A Tutorial and Call for More Routine Use.”</span> <em>Under Review</em>.</span></span>.</span> When we use a flat prior, we get the same estimate of 0.75.<label for="tufte-sn-40" class="margin-toggle sidenote-number">40</label><input type="checkbox" id="tufte-sn-40" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">40</span> High-level overviews of selection models are given in <span class="citation"><label for="tufte-mn-93" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-93" class="margin-toggle">McShane, Böckenholt, and Hansen (2016)<span class="marginnote">McShane, Blakeley B, Ulf Böckenholt, and Karsten T Hansen. 2016. <span>“Adjusting for Publication Bias in Meta-Analysis: An Evaluation of Selection Methods and Some Cautionary Notes.”</span> <em>Perspectives on Psychological Science</em> 11 (5): 730–49. <a href="https://doi.org/10.1177/1745691616662243">https://doi.org/10.1177/1745691616662243</a>.</span></span> and <span class="citation"><label for="tufte-mn-94" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-94" class="margin-toggle">Maier, VanderWeele, and Mathur (2021)<span class="marginnote">Maier, Maximilian, Tyler J VanderWeele, and Maya B Mathur. 2021. <span>“Using Selection Models to Assess Sensitivity to Publication Bias: A Tutorial and Call for More Routine Use.”</span> <em>Under Review</em>.</span></span>. for more methodological detail, see for example <span class="citation"><label for="tufte-mn-95" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-95" class="margin-toggle">Hedges (1984)<span class="marginnote">Hedges, Larry V. 1984. <span>“Estimation of Effect Size Under Nonrandom Sampling: The Effects of Censoring Studies Yielding Statistically Insignificant Mean Differences.”</span> <em>Journal of Educational Statistics</em> 9 (1): 61–85. <a href="https://doi.org/10.3102/10769986009001061">https://doi.org/10.3102/10769986009001061</a>.</span></span>, <span class="citation">(<a href="#ref-iyengar1988selection" role="doc-biblioref"><strong>iyengar1988selection?</strong></a>)</span>, and <span class="citation">(<a href="#ref-vevea1995general" role="doc-biblioref"><strong>vevea1995general?</strong></a>)</span>. For a tutorial on fitting and interpreting selection models, see <span class="citation"><label for="tufte-mn-96" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-96" class="margin-toggle">Maier, VanderWeele, and Mathur (2021)<span class="marginnote">Maier, Maximilian, Tyler J VanderWeele, and Maya B Mathur. 2021. <span>“Using Selection Models to Assess Sensitivity to Publication Bias: A Tutorial and Call for More Routine Use.”</span> <em>Under Review</em>.</span></span>.</span> In contrast, if we go in assuming that discrimination is likely to be absent or weak, we are biased downward in our eventual estimate of 0.69; if we go in assuming good discrimination, we end up biased upwards to 0.78.</p>
<p>Fisher’s original framwork for significance testing focused only on the <strong>null hypothesis</strong> of no discrimination. In contrast, the Bayesian estimation method here focuses on the magnitude of accuracy.<sup>[If you’re reading carefully, you might have noticed that we <em>could</em> have discovered that the estimate of accuracy was very similar to chance – more about this below.][</sup>MM: I entirely agree with the spirit of this, but I worry about framing this as “Fisherian NHST vs. Bayesian estimation” when the issue really is “Fisherian NHST” vs “any form of estimation with continuous inference.” We wouldn’t want to inadvertently reinforce the misconception that Bayesian methods <em>inherently</em> alleviate the central issues with NHST, even though Bayesian methods of course have numerous important merits.] The intuition we’d like you to get is that, if you are an experimentalist who cares about the magnitude of causal relationships (and we hope you are), then Fisher’s statistical approach isn’t ideally suited to your goals.[^MM: Yes, I like this framing in the final sentence much better.]</p>
<!-- TODO: HERE WOULD BE A GREAT PLACE FOR AN INTERACTIVE -->
</div>
<div id="effect-size" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Effect size</h2>
<p>With all our talk about estimation above, we didn’t say much about what precisely was being estimated. Often, researchers seek out some sort of common standardized way for describing the relationships they observe in the study.</p>
<p>For example, imagine that Mika and Nicholas are interested in examining whether a dog-petting intervention can reduce depression relative to a placebo. They use the same self-report depression measure, but Mika decides to make it a 10-point self-report scale (0 = “I feel blissful” to 10 = “I feel extremely depressed”), whereas Nicholas decides to make it a 100-point scale (1 = “I feel blissful” to 100 = “I feel extremely depressed”). Observing that the intervention led to a 1-point decrease in Mika’s scale is quite impressive. But observing a 1-point decrease in Nicholas’ scale? Not so much!</p>
<p>To ensure that we have a common currency, many researchers describe their observations using standardized metrics. A common example of a such a metric is Cohen’s <em>d</em>, which provides a standardized estimate of the difference between two means. There are many different ways to calculate Cohen’s <em>d</em> (Lakens, 2013), but there usually some variant of the following formula:</p>
<p><span class="math display">\[d = \frac{M_1- M_2}{SD_1}\]</span></p>
<p>In the above example, <span class="math inline">\(M_1\)</span> could be the depression scores of patients who were assigned to pet dogs, whereas <span class="math inline">\(M_2\)</span> would be the scores of patients who were assigned to a placebo condition. <span class="math inline">\(SD_1\)</span> refers refers to standard deviation of the participants who were randomly assigned to pet dogs. Note: researchers usually seek to pool the standard deviations of <em>both</em> groups, but (for simplicity) we will assume that both groups have the same standard deviation (and thus <span class="math inline">\(SD_1 = SD_2 = SD_{pooled}\)</span>).</p>
<p>Because Mika and Nicholas used different scales, they will nature observe different amount of variability. For example, if all participants indicate that they are between 2-8 on a 10-point scale, this should translate to a range of 20-80 on a 100-point scale. Similarly, a standard deviation of 2 on Mika’s scale should correspond to a standard deviation of 20 on Nicholas’ scale.</p>
<p>So let’s compare their results, assuming that participants in the placebo groups have a mean depression score at the center of the scale (5 out of 10; 50 out of 100) and that both Mika and Nicholas observe a 1-point decrease is depression in the dog-petting group.</p>
<p><span class="math display">\[{d_{Mika}} = \frac{M_1- M_2}{SD_1} = \frac{5- 4}{2} = \frac{1}{2} = 0.5\]</span></p>
<p><span class="math display">\[{d_{Nicholas}} = \frac{M_1- M_2}{SD_1} = \frac{50- 49}{20} = \frac{1}{20} =  .05\]</span></p>
<p>When using Cohen’s d, a value of .50 is often considered a strong effect, whereas a value of .05 would often be considered negligible (at least in the context of an intervention designed to improve depression).</p>
<p>Of course, there are many different standardized effect sizes that researchers can use. Although we described a common standardized effect size to describe differences in means, there are also standardized effect sizes for describing the amount of variance explained (e.g., Pearson’s <em>r</em>, R<sup>2</sup>, and <span class="math inline">\(\eta^2\)</span>) or relationships involving categorical variables (e.g., Odds Ratio). For a review, see… (Any recommendations?)</p>
<div id="pros-and-cons-of-standardization" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Pros and cons of standardization</h3>
<p>Pro: comparability across studies (e.g., school interventions to improve achievement?). Useful for meta-analysis (e.g., MA of facial feedback, which used a lot of different measures of emotion; infant consonant discrimination (cross method comparison)). Useful for a lot of power analysis software and packages (e.g., GPower and many packages in R).</p>
<p>Con: loss of information about measures and real-world predictions; dependence on baseline variability. Power analysis can only be done via annoying simulations. Not related to any real units. Often not very intuitive (have fun trying to explain what Cohen’s <em>d</em> is to a very curious non-scientist. Fun fact: the Wikipedia article on effect sizes has been flagged as “too technical for most readers to understand” since 2014!)</p>
</div>
</div>
<div id="variability-and-precision" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Variability and Precision</h2>
<div id="standard-error-of-the-mean" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Standard error of the mean</h3>
<p>Talk about standard error with respect to SD of sampling distribution</p>
</div>
<div id="confidence-intervals" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Confidence intervals</h3>
<p>CIs for inference</p>
<p>Confidence intervals: 95% of these regions will contain the TRUE parameter Remember frequentists - there is a TRUE parameter</p>
<p><a href="https://istats.shinyapps.io/ExploreCoverage/" class="uri">https://istats.shinyapps.io/ExploreCoverage/</a></p>
<p>But this is not our typical interpretation, which is that 95% chance parameter is in this interval That’s the BAYESIAN interpretation</p>
<p>Bayesian Estimation</p>
<p>Find the posterior distribution of the parameter of interest You can take its mean Its HPD (highest posterior density)</p>
<p>Confidence in confidence intervals: <a href="https://link.springer.com/article/10.3758/s13423-015-0947-8" class="uri">https://link.springer.com/article/10.3758/s13423-015-0947-8</a></p>
</div>
<div id="visualizing-variability" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Visualizing variability</h3>
<p>Error bar: - standard deviation (why is this bad)? - SEM - CI</p>
<!-- ::: {.interactive} -->
<!-- ⌨️ Interactive box: non-parametric simulations where you can shuffle data across groups a bunch of times and see what kind of distribution it produces by chance -->
<!-- ::: -->

</div>
</div>
</div>
<p style="text-align: center;">
<a href="3-ethics.html"><button class="btn btn-default">Previous</button></a>
<a href="5-inference.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="toc/toc.js"></script>


</body>
</html>
