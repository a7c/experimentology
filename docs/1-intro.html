<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 1 Introduction: theory and experiments | Experimentology" />
<meta property="og:type" content="book" />





<meta name="author" content="Michael C. Frank, Mika Braginsky, Julie Cachia, Nicholas Coles, Tom Hardwicke, Robert Hawkins, Maya Mathur, and Rondeline Williams" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Chapter 1 Introduction: theory and experiments | Experimentology">

<title>Chapter 1 Introduction: theory and experiments | Experimentology</title>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />




<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="toc/toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="part"><span><b>I Preliminaries</b></span></li>
<li><a href="1-intro.html#intro"><span class="toc-section-number">1</span> Introduction: theory and experiments</a></li>
<li><a href="2-replication.html#replication"><span class="toc-section-number">2</span> Replication and reproducibility</a></li>
<li><a href="3-ethics.html#ethics"><span class="toc-section-number">3</span> Ethics</a></li>
<li class="part"><span><b>II Statistics</b></span></li>
<li><a href="4-inference.html#inference"><span class="toc-section-number">4</span> Inference</a></li>
<li><a href="5-models.html#models"><span class="toc-section-number">5</span> Models</a></li>
<li class="part"><span><b>III Design and Planning</b></span></li>
<li><a href="6-measurement.html#measurement"><span class="toc-section-number">6</span> Measurement</a></li>
<li><a href="7-design.html#design"><span class="toc-section-number">7</span> Design of experiments</a></li>
<li><a href="8-sampling.html#sampling"><span class="toc-section-number">8</span> Sampling</a></li>
<li><a href="9-preregistration.html#preregistration"><span class="toc-section-number">9</span> Preregistration</a></li>
<li class="part"><span><b>IV Execution</b></span></li>
<li><a href="10-selection.html#selection"><span class="toc-section-number">10</span> Replicating or extending an existing study</a></li>
<li><a href="11-collection.html#collection"><span class="toc-section-number">11</span> Data collection</a></li>
<li><a href="12-management.html#management"><span class="toc-section-number">12</span> Data management and sharing</a></li>
<li class="part"><span><b>V Analysis and Reporting</b></span></li>
<li><a href="13-viz.html#viz"><span class="toc-section-number">13</span> Visualization</a></li>
<li><a href="14-eda.html#eda"><span class="toc-section-number">14</span> Exploratory data analysis</a></li>
<li><a href="15-writing.html#writing"><span class="toc-section-number">15</span> Reproducible writing</a></li>
<li><a href="16-meta.html#meta"><span class="toc-section-number">16</span> Meta-analysis</a></li>
<li><a href="17-conclusions.html#conclusions"><span class="toc-section-number">17</span> Conclusions</a></li>
<li class="part"><span><b>VI Appendices</b></span></li>
<li><a href="18-github.html#github"><span class="toc-section-number">18</span> Github Tutorial</a></li>
<li><a href="19-rmarkdown.html#rmarkdown"><span class="toc-section-number">19</span> R Markdown Tutorial</a></li>
<li><a href="20-tidyverse.html#tidyverse"><span class="toc-section-number">20</span> Tidyverse Tutorial</a></li>
<li><a href="21-ggplot.html#ggplot"><span class="toc-section-number">21</span> ggplot Tutorial</a></li>
<li><a href="22-instructors.html#instructors"><span class="toc-section-number">22</span> Instructor‚Äôs Guide</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="intro" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Introduction: theory and experiments</h1>
<div class="learning-goals">
<p>üçé Learning goals:</p>
<ul>
<li>Define ‚Äúexperiment‚Äù and ‚Äútheory‚Äù</li>
<li>Distinguish between bias and precision</li>
<li>Reason about the relationship between the experimental method and causal inference</li>
<li>Analyze features of an experiment that can lead to weaker or stronger tests of theory</li>
</ul>
</div>
<p>Welcome to Experimentology. This is a book about how to do psychology experiments! Much of what we cover in the book is about the nitty gritty of how to design your study, how to analyze your data, or even how to name your files! But before we can get into all that, we‚Äôre going to need to have a conversation about what an experiment is. And that in turn will lead us pretty quickly to talk about <strong>causality</strong>, since the unique contribution of experiments is to help us measure causal effects. That‚Äôs the first part of this chapter.</p>
<p>The second part of this chapter is about theory building, which is often one of the broader goals of doing an experiment. Sometimes you just want to see what happens, like a kid knocking down a tower. And sometimes you want to know the answer to a specific applied question, like ‚Äúwill giving a midterm vs.¬†weekly quizzes lead students in a class to perform better on the final.‚Äù But more often, our goal is to create psychological theories that help us explain and predict new observations.</p>
<p>Having discussed experiments and theories, we will then be in a position to talk a bit about what features an experiment will to contribute to theory, our last topic. But, as we‚Äôll do in most chapters in the book, we‚Äôll begin with a concrete example of theory building in psychology.</p>
<div class="case-study">
<p>üî¨ Case study: Generalization, similarity, and Bayesian inference</p>
<p>Let‚Äôs play a number game. Imagine I give you the number 16, and ask you how similar other numbers are to that one. You‚Äôll probably agree that 32 is more similar than 33. Is 96 more similar than 94? How about 6 vs.¬†8? Perhaps surprisingly, people‚Äôs judgments on such problems are quite systematic <span class="citation">(<label for="tufte-mn-1" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-1" class="margin-toggle">Tenenbaum 2000<span class="marginnote">Tenenbaum, Joshua B. 2000. <span>‚ÄúRules and Similarity in Concept Learning.‚Äù</span> <em>Advances in Neural Information Processing Systems</em> 12: 59‚Äì65.</span>)</span>: the more ‚Äúfeatures‚Äù that two numbers share, the more similar they are judged to be. Not only is 32 even like 16, it‚Äôs also a power of 2, and divisible by 8; in contrast, 33 shares none of these features.</p>
<p>Predicting arbitrary similarities of this sort is one of the hardest problems of psychology, and is likened to one of the biggest challenges for organisms: generalization. How do you take what you know and apply it to a new situation? One answer is that you use the same answer that has worked in similar situations ‚Äì but to do this kind of extrapolation, you need a notion of similarity.</p>
<p>Early learning theorists were obsessed with these issues of similarity and generalization because their view was that organisms (humans being no exception) learned conditioned associations with specific stimuli and then generalized from these associations to determine their response to new situations. So an animal conditioned to salivate to a tone of a particular frequency might salivate slightly less to a tone that was close in pitch, and salivate substantially less or not at all to a tone that was further away.</p>
<p>Roger Shepard worked for much of his career on understanding this problem of similarity and generalization, culminating in what he called the ‚Äúuniversal law of generalization,‚Äù which allowed generalizations to be derived in a wide range of stimulus spaces <span class="citation">(<label for="tufte-mn-2" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-2" class="margin-toggle">Shepard 1987<span class="marginnote">Shepard, Roger N. 1987. <span>‚ÄúToward a Universal Law of Generalization for Psychological Science.‚Äù</span> <em>Science</em> 237 (4820): 1317‚Äì23.</span>)</span>. The first step in this process was establishing a stimulus space. For a stimulus domain like size, color, or even speech sounds, he used a procedure called ‚Äúmultidimensional scaling‚Äù to infer how stimulus items could be placed in a low-dimensional (often 2D) Cartesian space. Then, when he visualized generalization gradients within this space, he found the incredibly consistent pattern shown in Figure <a href="1-intro.html#fig:shepard">1.1</a>. Working backwards from this pattern, he was able to establish a derivation for this exponential generalization gradient that allowed him to claim it as a universal law.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:shepard"></span>
<img src="images/intro/shepard1987.png" alt="Figure 1 from Shepard (1987). Generalization gradients for twelve diffent kinds of stimuli." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 1.1: Figure 1 from Shepard (1987). Generalization gradients for twelve diffent kinds of stimuli.<!--</p>-->
<!--</div>--></span>
</p>
<p>The pattern shown in Shepard‚Äôs work is an example of <strong>inductive theory building</strong>. In the vocabulary we‚Äôre developing, Shepard ran (or obtained the data from) <strong>randomized experiments</strong> in which the <strong>manipulation</strong> was stimulus dimension (e.g., circle size) and the <strong>measure</strong> was an explicit similarity judgment (e.g., how similar is this circle to that one). Then the theory that Shepard proposes links three <strong>constructs</strong> ‚Äì latent entities whose relationships the theory specifies. In particular, 1) similarity is used to derive 2) an internal psychological space, and 3) generalizations are then derived from distance in this space.<label for="tufte-sn-1" class="margin-toggle sidenote-number">1</label><input type="checkbox" id="tufte-sn-1" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">1</span> If you have some background in the philosophy of science, you may be ready to call the philosophy police! If you‚Äôre feeling that way, just wait ‚Äì we‚Äôll try to link some of our ideas to at least a lay understanding of the philosophy of science literature!</span></p>
<p>Could it be that the ‚Äúnumber game‚Äù judgments above are the same kinds of generalizations that Shepard observed in his analyses of perceptual data? <span class="citation"><label for="tufte-mn-3" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-3" class="margin-toggle">Tenenbaum and Griffiths (2001)<span class="marginnote">Tenenbaum, Joshua B, and Thomas L Griffiths. 2001. <span>‚ÄúGeneralization, Similarity, and Bayesian Inference.‚Äù</span> <em>Behavioral and Brain Sciences</em> 24 (4): 629‚Äì40.</span></span> presented a theory of similarity that preserved almost all of Shepard‚Äôs assumptions, but did not require a continuous metric space at all. In its simplest form, the model just stated that the strength of a generalization was proportional to its specificity. This simplification allowed the model to be used to compute similarity and generalization for arbitrary domains, even the features of whole numbers! So for example, the property of being even does not confer much similarity because it is shared by half of all whole numbers; in contrast, being a power of 2 conveys much more because it is rarer. When applied to the number game, this model produced a close correspondence with human judgments.</p>
<p>Since the development of this generalization model, it has been applied to a wide variety of domains including word learning <span class="citation">(<label for="tufte-mn-4" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-4" class="margin-toggle">Xu and Tenenbaum 2007<span class="marginnote">Xu, Fei, and Joshua B Tenenbaum. 2007. <span>‚ÄúWord Learning as Bayesian Inference.‚Äù</span> <em>Psychological Review</em> 114 (2): 245.</span>)</span>, object exploration <span class="citation">(<label for="tufte-mn-5" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-5" class="margin-toggle">Gweon, Tenenbaum, and Schulz 2010<span class="marginnote">Gweon, Hyowon, Joshua B Tenenbaum, and Laura E Schulz. 2010. <span>‚ÄúInfants Consider Both the Sample and the Sampling Process in Inductive Generalization.‚Äù</span> <em>Proceedings of the National Academy of Sciences</em> 107 (20): 9066‚Äì71.</span>)</span>, and sequential rule learning <span class="citation">(<label for="tufte-mn-6" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-6" class="margin-toggle">Frank and Tenenbaum 2011<span class="marginnote">Frank, Michael C, and Joshua B Tenenbaum. 2011. <span>‚ÄúThree Ideal Observer Models for Rule Learning in Simple Languages.‚Äù</span> <em>Cognition</em> 120 (3): 360‚Äì71.</span>)</span>. Yet this model has been critiqued as psychologically implausible <span class="citation">(<label for="tufte-mn-7" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-7" class="margin-toggle">Endress 2013<span class="marginnote">Endress, Ansgar D. 2013. <span>‚ÄúBayesian Learning and the Psychology of Rule Induction.‚Äù</span> <em>Cognition</em> 127 (2): 159‚Äì76.</span>)</span>, since it requires people to know a priori how specific each particular feature is. Further, the general framework within which the model was posed has been critiqued extensively for its assumption that human reasoning conforms to optimal statistical computations <span class="citation">(<label for="tufte-mn-8" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-8" class="margin-toggle">Jones and Love 2011<span class="marginnote">Jones, Matt, and Bradley C Love. 2011. <span>‚ÄúBayesian Fundamentalism or Enlightenment? On the Explanatory Status and Theoretical Contributions of Bayesian Models of Cognition.‚Äù</span> <em>Behavioral and Brain Sciences</em> 34 (4): 169.</span>)</span>. One way of thinking about these critiques is that they question which phenomena are in the scope of the theory: and in particular, whether Bayesian models should explain human psychological processes, or whether they are just a descriptive account of certain average behavioral outcomes.</p>
<p>In our discussion below, we‚Äôll look at the broader goal of theory building and how this kind of critique echoes some of the main tensions around what theories are for and how theories can be evaluated. Shepard wrote in the conclusion of his 1987 paper, ‚ÄúPossibly, behind the diverse behaviors of humans and animals, as behind the various motions of planets and stars, we may discern the operation of universal laws.‚Äù While Shepard‚Äôs dream is an ambitious one, it defines one potential ideal for psychological theorizing.</p>
</div>
<div id="what-is-an-experiment-and-why-would-you-do-one" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> What is an experiment, and why would you do one?</h2>
<!-- - On one hand, experiments are ‚Äúthe worst way to learn about the world‚Äù (in the words of one of our mentors). ‚ÄúYou can‚Äôt play 20 questions with nature and win‚Äù (Newell 1973). But experiments are also one of our best tools for making strong causal inferences about the hidden structure of the world. They allow us to not just observe the world but to systematically intervene on it. -->
<!-- - We used to just poke things or people and measure what happened (see Hacking, 1990 on the 19th century craze of just measuring everything for fun.) Now we typically want our experiments to resolve deeper questions or test hypotheses. -->
<p>When you do an experiment, you change the world in order to learn something new. This common-sense definition has two parts to it: the <strong>manipulation</strong> and the <strong>measure</strong>. The manipulation is the thing you are doing to the world, and the measure is the way you quantify the effects that your actions had. The manipulation licenses <strong>causal inference</strong>, which is our first topic. A second ingredient, <strong>randomization</strong>, licenses inferences about the locus of the causal effect. We‚Äôll talk about each of these in turn.</p>
<p>Let‚Äôs think through an example. If you‚Äôve ever tried to write a paper or even a tricky email while listening to vocal music with lyrics, you might have had the feeling that the lyrics of the music interfered with your own writing. Let‚Äôs call this the ‚ÄúDylan Hypothesis‚Äù ‚Äì listening to music like Bob Dylan‚Äôs lyrically rich songs decreases writing skill.</p>
<p>The Dylan Hypothesis is a <strong>causal hypothesis</strong> ‚Äì meaning that we ascribe responsibility for the decrease in writing skill to this factor particularly.<label for="tufte-sn-2" class="margin-toggle sidenote-number">2</label><input type="checkbox" id="tufte-sn-2" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">2</span> Defining causality is one of the trickiest and oldest problems in philosophy, and we won‚Äôt attempt to solve it here! But from a psychological perspective, we‚Äôre fond of <span class="citation">(<a href="#ref-lewis1973" role="doc-biblioref"><strong>lewis1973?</strong></a>)</span>‚Äôs ‚Äúcounterfactual‚Äù analysis of causality. On this view, the Dylan Hypothesis amounts to the claim that, in some situation, if we <em>hadn‚Äôt</em> played Dylan, we <em>wouldn‚Äôt</em> have experienced a decrement in writing ability.</span> In what follows, we‚Äôll try to be precise about the causal inferences we‚Äôre discussing.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:intro-dylan1"></span>
<img src="images/intro/dylan1.png" alt="The hypothesized causal relationship of the Dylan Hypothesis." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 1.2: The hypothesized causal relationship of the Dylan Hypothesis.<!--</p>-->
<!--</div>--></span>
</p>
<p>In Figure <a href="#intro-dylan"><strong>??</strong></a>, we show the Dylan Hypothesis using a kind of diagram called a <strong>causal graphical model</strong> <span class="citation">(<label for="tufte-mn-9" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-9" class="margin-toggle">Pearl 1998<span class="marginnote">Pearl, Judea. 1998. <span>‚ÄúGraphical Models for Probabilistic and Causal Reasoning.‚Äù</span> <em>Quantified Representation of Uncertainty and Imprecision</em>, 367‚Äì89.</span>)</span>. Our outcome is writing skill (Y) and our predictor is Dylan listening (X). The edge between them represents a hypothesized causal relationship. Dylan listening is hypothesized have to a causal effect on writing skill, and not vice versa. Now let‚Äôs talk about how experiments allow us to make these causal inferences.</p>
<div id="causal-inference" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Causal inference</h3>
<p>Most science textbooks don‚Äôt start a definition of what an experiment is; psychology textbooks are an exception <span class="citation">(<label for="tufte-mn-10" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-10" class="margin-toggle">Winston and Blais 1996<span class="marginnote">Winston, Andrew S., and Daniel J. Blais. 1996. <span>‚ÄúWhat Counts as an Experiment?: A Transdisciplinary Analysis of Textbooks, 1930-1970.‚Äù</span> <em>The American Journal of Psychology</em> 109 (4): 599‚Äì616. <a href="http://www.jstor.org/stable/1423397">http://www.jstor.org/stable/1423397</a>.</span>)</span>. Perhaps this is because experiments are a critical method for making strong causal inferences, which are otherwise in short supply in psychology. The role of causality is much more straightforward in the physical sciences ‚Äì so straightforward that not much time needs to be spent on it.</p>
<p>In contrast, causal inference is a central issue in any field that deals with human beings. People are very complex systems. Even from an intuitive perspective, there are many obvious factors ‚Äì personality, values, culture, physiology, genes ‚Äì that influence any individual choice. Further, scientists typically have relatively limited opportunities to intervene on complex social systems. Although we can carry out some kinds of experiments within ethical and practical limits, we‚Äôre not just allowed to go around doing what we want to the people around us, just to see what happens! This situation stands in stark contrast to the physical sciences, where in the service of your analysis, you can do pretty much anything you want with a chemical solution.</p>
<p>Returning to the Dylan Hypothesis, suppose we did an observational study where we measured our variables ‚Äì Dylan listening and writing quality ‚Äì in a large population.<label for="tufte-sn-3" class="margin-toggle sidenote-number">3</label><input type="checkbox" id="tufte-sn-3" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">3</span> This sounds impractical, but let‚Äôs imagine some kind of dystopian, Google Docs+Spotify surveillance in which the companies team up to monitor your writing and listening habits and provide quantitative estimates of writing quality and lyric density. Big data!</span> We might compute a correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> and find some non-zero relationship between them. If we did this study, you might predict that listening to Dylan would be related to better writing.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:intro-dylan2"></span>
<img src="images/intro/dylan2.png" alt="Cofounding with age in the Dylan Hypothesis." width="\linewidth"  />
<!--
<p class="caption marginnote">-->Figure 1.3: Cofounding with age in the Dylan Hypothesis.<!--</p>-->
<!--</div>--></span>
</p>
<p>Can we make a causal inference? No.¬†Correlation doesn‚Äôt equal causation here. There is (at least one) confounding third variable: age (<span class="math inline">\(Z\)</span>). Age is positively related to both Dylan listening and writing skill in our population of interest. Older people tend to be good writers and also tend to be more into folk rockers.<label for="tufte-sn-4" class="margin-toggle sidenote-number">4</label><input type="checkbox" id="tufte-sn-4" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">4</span> We won‚Äôt even put a question mark on this edge because it seems likely to be true.</span></p>
<p>But: the causal relationship of age to our other two variables means that variation in Z can induce a correlation in X and Y, even in the absence of a true causal link. We can say that age is a confound in estimating the Dylan-writing skill relationship: it‚Äôs a variable that is correlated with both our predictor and our outcome variables.</p>
<p>To get gold-standard evidence about causality, we need to do an experiment. (We won‚Äôt discuss statistical techniques for inferring causality, which can be useful but don‚Äôt give you gold standard evidence anyway; review here).</p>
<p>Experiments are when we intervene on the world and measure the consequences. Here, this means forcing some people to listen to Dylan. In the language of graphical models, if we control the Dylan listening, that means that variable X is causally exogenous. (Exogenous means that it‚Äôs not caused by anything else in the system). We ‚Äúsnipped‚Äù the causal link between age and Dylan listening.</p>
<p><label for="tufte-mn-11" class="margin-toggle">‚äï</label><input type="checkbox" id="tufte-mn-11" class="margin-toggle"><span class="marginnote"><span style="display: block;"><img src="images/dylan3.png"/></span></span></p>
<p>So now we can ‚Äúwiggle‚Äù the Dylan listening variable ‚Äì change it experimentally ‚Äì and see if we detect any changes in writing skill. We do this by randomly assigning individuals to listen to Dylan or not and then measuring writing during the assigned listening (or non-listening) period. This is a ‚Äúbetween-subjects‚Äù design. We can use our randomized experiment to get a measure of the average treatment effect of Dylan, the size of the causal effect of the intervention on the outcome.</p>
<!-- In this simple experiment, the ATE is estimated by the regression Y ~ X (for ease of exposition, I'm not going to discuss so-called mixed models, which model variation across subjects and/or experimental items). That's the elegant logic of randomized experiments: the difference between condition gives you the average effect. -->
</div>
<div id="confounding" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Confounding</h3>
<p>When we talk about experiments in psychology, we are also talking about <strong>randomized experiments</strong>. In the physical sciences, we can sometimes intervene on a system, comparing before and after the intervention. An example of a simple experiment would be to measure the temperature of some water, heat it, and then measure the temperature again. We feel relatively warranted in making the inference that the heat caused the temperature to rise. That logic doesn‚Äôt work as well with people.</p>
<p>Say we do an analogous psychology experiment. We measure their attitudes about an issue. Then we give them something to read about that issue. And then we measure</p>
<p><span class="citation"><label for="tufte-mn-12" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-12" class="margin-toggle">Mill (1869)<span class="marginnote">Mill, John Stuart. 1869. <em>A System of Logic, Ratiocinative and Inductive: Being a Connected View of the Princilples of Evidence and the Methods of Scientific Investigation</em>. Harper; brothers.</span></span></p>
<p>To quote from <span class="citation"><label for="tufte-mn-13" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-13" class="margin-toggle">Mill (1869)<span class="marginnote">Mill, John Stuart. 1869. <em>A System of Logic, Ratiocinative and Inductive: Being a Connected View of the Princilples of Evidence and the Methods of Scientific Investigation</em>. Harper; brothers.</span></span>, ‚ÄúIf an instance in which the phenomenon under investigation occurs, and an instance in which it does not occur, have every circumstance in common save one, that one occurring only in the former; the circumstance in which alone the two instances differ, is the effect, or the cause, or an indispensable part of the cause, of the phenomenon.‚Äù Rando</p>
</div>
<div id="causal-inference-1" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Causal inference</h3>
<ul>
<li>Causal graphical models as an approach to understanding causal inference via counterfactuals (Pearl and Mackenzie 2018).</li>
</ul>
</div>
</div>
<div id="what-is-a-theory" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> What is a theory?</h2>
<p>The entities we theorize about are unseen. We call these <strong>constructs</strong>.<label for="tufte-sn-5" class="margin-toggle sidenote-number">5</label><input type="checkbox" id="tufte-sn-5" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">5</span> Why are they called constructs? HISTORY OF THE TERM?</span> Constructs are hypothesized abstract entities, which can range widely in specificity. g (general intelligence) is the classic psychological example of a broad construct. In contrast, an example of a very specific construct is <span class="math inline">\(\alpha\)</span>, the ‚Äúrationality‚Äù parameter in RSA models that controls how greedily RSA agents choose the higher-probability choice.<label for="tufte-sn-6" class="margin-toggle sidenote-number">6</label><input type="checkbox" id="tufte-sn-6" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">6</span> A tradition of research in cognitive science posits that human knowledge is organized into theories <span class="citation">(<a href="#ref-gopnikwellman" role="doc-biblioref"><strong>gopnikwellman?</strong></a>)</span>, and that in particular we organize our knowledge about other people into an <strong>intuitive theory of psychology</strong>. This intuitive theory includes concepts like ‚Äúbelief,‚Äù ‚Äúdesire,‚Äù and ‚Äúemotion‚Äù <span class="citation">(<a href="#ref-wellmanXYZ" role="doc-biblioref"><strong>wellmanXYZ?</strong></a>)</span>, but it‚Äôs important to distinguish the constructs we posit in psychological theories from the terms in our intuitive theories. Often one is grounded in the other, but the failure to distinguish the two can lead to sloppy reasoning..</span></p>
<p>Theories then are groups of assumptions about the relationships between these constructs. Occasionally, defining a construct is enough to describe a theory. Defining general intelligence as g, the shared variance between different tests of intelligence, is itself a theoretically-loaded move [critique of IQ here? maybe cite Shalizi]. But more frequently the constructs don‚Äôt mean anything by themselves (think about <span class="math inline">\(\alpha\)</span> in RSA!) ‚Äì they gain their meaning by their relationship to other constructs.</p>
<p>This web of constructs and assumptions is what <span class="citation">(<a href="#ref-cronbach1958" role="doc-biblioref"><strong>cronbach1958?</strong></a>)</span> referred to as a ‚Äúnomological network‚Äù ‚Äì a set of proposals about how different entities are connected to one another. (We‚Äôll return to this idea in Chapter <a href="6-measurement.html#measurement">6</a> when we talk about measurement validity). Calling the theory a ‚Äúnetwork‚Äù sounds like it‚Äôs a <strong>structural equation model</strong> (SEM) where there are circles and lines and the lines represent something akin to the correlations between the numbers in the circles. That‚Äôs one way to define a psychological theory, but it‚Äôs not the only way!</p>
<p>There are many different frameworks for describing psychological constructs and their relationships. SEM is just one framework, built on linear regression. But the probabilistic modeling framework used in RSA is another such framework, where a system of equations defines a conditional probability distribution <span class="citation">(<label for="tufte-mn-14" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-14" class="margin-toggle">Goodman, Tenenbaum, and Contributors 2016<span class="marginnote">Goodman, Noah D, Joshua B. Tenenbaum, and The ProbMods Contributors. 2016. <span>‚Äú<span class="nocase">Probabilistic Models of Cognition</span>.‚Äù</span> <a href="http://probmods.org/v2">http://probmods.org/v2</a>.</span>)</span>. Other computational frameworks from procedural models like ACT-R <span class="citation">(<a href="#ref-anderson" role="doc-biblioref"><strong>anderson?</strong></a>)</span> to connectionist models <span class="citation">(<a href="#ref-rethinkinginnateness" role="doc-biblioref"><strong>rethinkinginnateness?</strong></a>)</span> and modern neural networks <span class="citation">(<a href="#ref-naturereviewbengio" role="doc-biblioref"><strong>naturereviewbengio?</strong></a>)</span> provide other frameworks.</p>
<p>None of these computational or formal artifacts are themselves psychological theories, but all of them can be used to create psychological theories via the mapping of constructs onto entities in the model and the use of the principles of the formalism to instantiate psychological hypotheses or assumptions.<label for="tufte-sn-7" class="margin-toggle sidenote-number">7</label><input type="checkbox" id="tufte-sn-7" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">7</span> We might also want to add to the theory some assumptions about how these constructs ground out into measurements. Some philosophers of science distinguish between the ‚Äúcore‚Äù assumptions of a theory and the ‚Äúperiphery‚Äù ‚Äì and we might be tempted to say that specific measurements are peripheral. If we came up with a better measure of the construct, or it turned out that our measure wasn‚Äôt particularly good, we could replace it without too much damage to the underlying theory.</span></p>
<p>Theories can then be tested via their ability to explain existing patterns of data and to predict new data. There is some tension between these. Theories with high predictive value are not necessarily causal or parsimonious (e.g., a black-box neural network model that predicts heart disease risk). Meanwhile, theories with high explanatory value may only account for a small proportion of overall variance in a behavior (e.g.¬†a theory of lexical priming that introduces a new, causal role of accessibility).</p>
<p><span class="citation"><label for="tufte-mn-15" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-15" class="margin-toggle">Navarro (2021)<span class="marginnote">Navarro, Danielle J. 2021. <span>‚ÄúIf Mathematical Psychology Did Not Exist We Might Need to Invent It: A Comment on Theory Building in Psychology.‚Äù</span> <em>Perspectives on Psychological Science</em>, 1745691620974769.</span></span></p>
<div id="popper-kuhn-and-lakatos-oh-my" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Popper, Kuhn, and Lakatos, oh my!</h3>
<p>Defining features of science, e.g.¬†mertonian norms - organized skepticism.</p>
<p>popper</p>
<p>lakatos</p>
<p>kuhn</p>
<p>bayesian theories</p>
<p>holism and the Duhem-Quine thesis.</p>
</div>
<div id="practicalities-of-theory-testing-in-psychology" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Practicalities of theory-testing in psychology</h3>
<p>We also typically want to make <strong>generalizations</strong> about causal relationships that go beyond the specifics of the case we are studying. For example, if we study a particular group of people,w e</p>
<div class="ethics-box">
<p>üåø Ethics box: Who are we theorizing about? How does this theory build on prior history? And what are the consequences of that theorizing? Example: the input-uptake relationship in language learning is a well-supported idea, but it can become weaponized against communities of color (Sperry, Sperry, and Miller 2019).</p>
</div>
</div>
</div>
<div id="how-to-do-experiments-that-help-build-theory" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> How to do experiments that help build theory?</h2>
<ul>
<li><p>Introducing the concepts of precision and bias (dartboard analogy).</p>
<ul>
<li>Precision of measurement is a foundational value allowing for cumulative progress and falsification; measuring null effects with precision can be just as important.</li>
<li>Precise measurements must also be unbiased to be helpful in theory construction ‚Äì or else theories risk reifying bias into their constructs.</li>
</ul></li>
<li><p>‚ÄúRisky tests‚Äù (Meehl 1978) vs.¬†‚Äúflexible theories‚Äù (Roberts and Pashler 2000)</p>
<ul>
<li>Formal relationship to Bayes Occam‚Äôs Razor and example of spreading bets across every horse vs.¬†placing all your money on one horse (if that one horse wins, you get a much higher payoff in the second case).</li>
</ul></li>
<li><p>Each experiment can be viewed as a single operationalization of an underlying theory, thus the value of meta-analysis to pool across these instantiations (see Chapter 16).</p></li>
<li><p>Experiments as ‚Äúbets‚Äù - riskier or costlier bets more impressive</p></li>
</ul>
</div>
<div id="what-does-an-ideal-experiment-look-like" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> What does an ideal experiment look like?</h2>
<p>a bet
a formula
an aesthetic object</p>

</div>
</div>
<p style="text-align: center;">
<a href="index.html"><button class="btn btn-default">Previous</button></a>
<a href="2-replication.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="toc/toc.js"></script>


</body>
</html>
